{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e3ca356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting preprocessor...\n",
      "Fitting Random Forest for feature selection...\n",
      "Top 30 features selected:\n",
      "              feature  importance\n",
      "41          Qual*Area    0.581971\n",
      "37            TotalSF    0.118526\n",
      "4         OverallQual    0.049219\n",
      "12        TotalBsmtSF    0.018893\n",
      "26         GarageCars    0.017128\n",
      "9          BsmtFinSF1    0.016276\n",
      "39                Age    0.012849\n",
      "7        YearRemodAdd    0.010143\n",
      "3             LotArea    0.009905\n",
      "6           YearBuilt    0.008749\n",
      "27         GarageArea    0.008651\n",
      "38          TotalBath    0.008248\n",
      "5         OverallCond    0.008085\n",
      "46        MSZoning_RM    0.007540\n",
      "226      CentralAir_N    0.006521\n",
      "13           1stFlrSF    0.005922\n",
      "16          GrLivArea    0.005103\n",
      "11          BsmtUnfSF    0.005055\n",
      "2         LotFrontage    0.004873\n",
      "25        GarageYrBlt    0.004620\n",
      "227      CentralAir_Y    0.004166\n",
      "0                  Id    0.003744\n",
      "14           2ndFlrSF    0.003674\n",
      "237    KitchenQual_TA    0.002963\n",
      "35             MoSold    0.002762\n",
      "29        OpenPorchSF    0.002738\n",
      "42   MSZoning_C (all)    0.002557\n",
      "174      ExterQual_TA    0.002388\n",
      "24         Fireplaces    0.002258\n",
      "188       BsmtQual_Gd    0.002236\n",
      "XGBoost CV Score with top 30 features: 0.01795\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "\n",
    "# Data preprocessing function remains the same\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Handle missing values and add new features.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop columns with high NaN ratio\n",
    "    df.drop(columns=[\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\"], inplace=True, errors=\"ignore\")\n",
    "    \n",
    "    # Fill known missing values\n",
    "    df[\"LotFrontage\"] = df[\"LotFrontage\"].fillna(df[\"LotFrontage\"].median())\n",
    "    df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].fillna(df[\"YearBuilt\"])\n",
    "    \n",
    "    # Categorical columns\n",
    "    cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].fillna(\"None\")\n",
    "    \n",
    "    # Feature engineering\n",
    "    df[\"TotalSF\"] = df[\"TotalBsmtSF\"] + df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]\n",
    "    df[\"TotalBath\"] = df[\"FullBath\"] + 0.5 * df[\"HalfBath\"] + df[\"BsmtFullBath\"] + 0.5 * df[\"BsmtHalfBath\"]\n",
    "    df[\"Age\"] = df[\"YrSold\"] - df[\"YearBuilt\"]\n",
    "    df[\"Remodeled\"] = (df[\"YearBuilt\"] != df[\"YearRemodAdd\"]).astype(int)\n",
    "    df[\"Qual*Area\"] = df[\"GrLivArea\"] * df[\"OverallQual\"]\n",
    "    \n",
    "    # Log-transform skewed numeric features\n",
    "    numeric_feats = df.select_dtypes(include=np.number).columns\n",
    "    skewed_feats = df[numeric_feats].apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "    high_skew = skewed_feats[skewed_feats > 0.75].index\n",
    "    df[high_skew] = np.log1p(df[high_skew])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load and preprocess data\n",
    "train_df = pd.read_csv(\"/Users/dubeaditya/Desktop/BF House Price Predicition/Data/train.csv\")\n",
    "test_df = pd.read_csv(\"/Users/dubeaditya/Desktop/BF House Price Predicition/Data/test.csv\")\n",
    "\n",
    "train_processed = preprocess_data(train_df)\n",
    "test_processed = preprocess_data(test_df)\n",
    "\n",
    "# Prepare feature lists\n",
    "numeric_features = train_processed.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = train_processed.select_dtypes(include=\"object\").columns.tolist()\n",
    "\n",
    "if \"SalePrice\" in numeric_features:\n",
    "    numeric_features.remove(\"SalePrice\")\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', RobustScaler()),\n",
    "            ('transformer', PowerTransformer(method='yeo-johnson'))\n",
    "        ]), numeric_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ]), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Prepare initial data\n",
    "X = train_processed.drop(columns=[\"SalePrice\"])\n",
    "y = np.log1p(train_df[\"SalePrice\"])\n",
    "X_test = test_processed\n",
    "\n",
    "# Fit preprocessor separately\n",
    "print(\"Fitting preprocessor...\")\n",
    "preprocessor.fit(X)\n",
    "X_transformed = preprocessor.transform(X)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "preprocessed_feature_names = (\n",
    "    numeric_features + \n",
    "    preprocessor.named_transformers_['cat']\n",
    "        .named_steps['encoder']\n",
    "        .get_feature_names_out(categorical_features).tolist()\n",
    ")\n",
    "\n",
    "# Fit Random Forest for feature selection\n",
    "print(\"Fitting Random Forest for feature selection...\")\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_transformed, y)\n",
    "\n",
    "# Select top 30 features\n",
    "feature_selector = SelectFromModel(rf_model, max_features=30, threshold=-np.inf, prefit=True)\n",
    "X_selected = feature_selector.transform(X_transformed)\n",
    "X_test_selected = feature_selector.transform(X_test_transformed)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_mask = feature_selector.get_support()\n",
    "selected_features = [preprocessed_feature_names[i] for i in range(len(preprocessed_feature_names)) if selected_mask[i]]\n",
    "\n",
    "print(\"Top 30 features selected:\")\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': preprocessed_feature_names,\n",
    "    'importance': rf_model.feature_importances_\n",
    "})\n",
    "print(feature_importance_df.nlargest(30, 'importance'))\n",
    "\n",
    "# Create XGBoost pipeline (no preprocessor since data is already transformed)\n",
    "xgb_model = Pipeline(steps=[\n",
    "    ('regressor', xgb.XGBRegressor(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Cross-validation with selected features\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "xgb_scores = -cross_val_score(xgb_model, X_selected, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "print(f\"XGBoost CV Score with top 30 features: {np.mean(xgb_scores):.5f}\")\n",
    "\n",
    "# Train model on full training data with selected features\n",
    "xgb_model.fit(X_selected, y)\n",
    "\n",
    "# Make predictions\n",
    "xgb_pred = np.expm1(xgb_model.predict(X_test_selected))\n",
    "\n",
    "# Export results\n",
    "output = pd.DataFrame({\"Id\": test_df[\"Id\"], \"SalePrice\": xgb_pred})\n",
    "output.to_csv(\"xgboost_predictions_rf_selection.csv\", index=False)\n",
    "\n",
    "# Save the trained model, preprocessor, and selected features\n",
    "def save_model_and_features(model, preprocessor, selected_features):\n",
    "    \"\"\"Save trained XGBoost model, preprocessor, and selected features to pickle files\"\"\"\n",
    "    with open('xgboost_model_rf_selection.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    with open('preprocessor.pkl', 'wb') as f:\n",
    "        pickle.dump(preprocessor, f)\n",
    "    with open('selected_features.pkl', 'wb') as f:\n",
    "        pickle.dump(selected_features, f)\n",
    "\n",
    "# Save the model and features\n",
    "save_model_and_features(xgb_model, preprocessor, selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb1a7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
